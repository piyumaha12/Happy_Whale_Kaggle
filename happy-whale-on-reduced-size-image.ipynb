{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## This Notebook is created to experiment with input pipelines of tensorflow","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nimport os\nimport glob\nimport cv2\n%config Completer.use_jedi = False","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-21T17:26:52.815213Z","iopub.execute_input":"2022-02-21T17:26:52.815822Z","iopub.status.idle":"2022-02-21T17:26:55.143824Z","shell.execute_reply.started":"2022-02-21T17:26:52.815726Z","shell.execute_reply":"2022-02-21T17:26:55.142696Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras.layers import Dense,Conv2D,MaxPooling2D,Flatten,Reshape,Dropout\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator","metadata":{"execution":{"iopub.status.busy":"2022-02-21T17:26:57.001790Z","iopub.execute_input":"2022-02-21T17:26:57.002136Z","iopub.status.idle":"2022-02-21T17:27:03.894986Z","shell.execute_reply.started":"2022-02-21T17:26:57.002101Z","shell.execute_reply":"2022-02-21T17:27:03.893759Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2022-02-21T17:27:03.897140Z","iopub.execute_input":"2022-02-21T17:27:03.897509Z","iopub.status.idle":"2022-02-21T17:27:04.716352Z","shell.execute_reply.started":"2022-02-21T17:27:03.897455Z","shell.execute_reply":"2022-02-21T17:27:04.715340Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"np.random.seed(45)\ntf.random.set_seed(45)","metadata":{"execution":{"iopub.status.busy":"2022-02-21T17:27:04.720542Z","iopub.execute_input":"2022-02-21T17:27:04.720860Z","iopub.status.idle":"2022-02-21T17:27:04.726959Z","shell.execute_reply.started":"2022-02-21T17:27:04.720826Z","shell.execute_reply":"2022-02-21T17:27:04.725773Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"INPUT_PATH = '/kaggle/input'\nTRAINING_PATH = '../input/jpeg-happywhale-128x128/train_images-128-128/train_images-128-128/'\nIMAGE_SIZE = 128\nIMAGE_SIZE_CUSTOM = 100\nSHUFFLE = 2589\nBATCH = 50\nAUTO = tf.data.AUTOTUNE","metadata":{"execution":{"iopub.status.busy":"2022-02-21T17:27:12.683690Z","iopub.execute_input":"2022-02-21T17:27:12.684638Z","iopub.status.idle":"2022-02-21T17:27:12.690851Z","shell.execute_reply.started":"2022-02-21T17:27:12.684579Z","shell.execute_reply":"2022-02-21T17:27:12.689834Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"len(os.listdir(TRAINING_PATH))","metadata":{"execution":{"iopub.status.busy":"2022-02-21T17:27:13.470236Z","iopub.execute_input":"2022-02-21T17:27:13.470578Z","iopub.status.idle":"2022-02-21T17:27:15.533283Z","shell.execute_reply.started":"2022-02-21T17:27:13.470546Z","shell.execute_reply":"2022-02-21T17:27:15.532322Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"51033"},"metadata":{}}]},{"cell_type":"code","source":"IMAGE_NAMES = os.listdir(TRAINING_PATH)[:1000]","metadata":{"execution":{"iopub.status.busy":"2022-02-21T17:27:16.536944Z","iopub.execute_input":"2022-02-21T17:27:16.537301Z","iopub.status.idle":"2022-02-21T17:27:16.570036Z","shell.execute_reply.started":"2022-02-21T17:27:16.537261Z","shell.execute_reply":"2022-02-21T17:27:16.568852Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"<h2> For easy to use and fast to train, I am taking only 1000 rows for training and validation </h2>","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.random.set_state = 45\nnp.random.seed(45)\ndf = pd.DataFrame(IMAGE_NAMES, columns = ['image'])\ndf['labels'] = np.random.randint(0, 5, size = 1000, )\ndf['labels_str'] = df.labels.astype('string')  # for ImageGenerator pipeline and for flow_from_dataframe\ndf['image_path'] = TRAINING_PATH + df['image']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head(5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Analysis","metadata":{}},{"cell_type":"code","source":"image = tf.io.read_file(df.image_path[0])\nimage = tf.image.decode_jpeg(image)\nplt.imshow(image)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"AT =tf.image.resize(image, size = [IMAGE_SIZE_CUSTOM, IMAGE_SIZE_CUSTOM])\nAT = tf.cast(AT, tf.float32)/255.0","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(AT.shape)\nplt.imshow(AT)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(nrows = 5, ncols = 5, figsize = (20,15))\nfor i, path in enumerate(df.image_path[:25]):\n    image_1 = tf.io.read_file(path)\n    image_1 = tf.image.decode_jpeg(image_1)\n    ax.ravel()[i].imshow(image_1)\n    ax.ravel()[i].set_axis_off()\n    plt.tight_layout()\nplt.show()\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"px.bar(data_frame = df.labels.value_counts(), y = 'labels', color = 'labels', )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Input pipeline \n\nThere are many ways to create input pipeline like:\n1. using TFRecord\n2. Using Image directory ","metadata":{}},{"cell_type":"code","source":"train_datagen = ImageDataGenerator(rescale= 1./255,\n                                  horizontal_flip = True,\n                                  validation_split = 0.2)\nvalidation_datagen = ImageDataGenerator(rescale=1./255,\n                                       validation_split = 0.2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head(1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_set = train_datagen.flow_from_dataframe(df,\n                                        TRAINING_PATH,\n                                        x_col = 'image', \n                                                y_col = 'labels_str',\n                                                seed = 45,\n                                                target_size = (IMAGE_SIZE, IMAGE_SIZE),\n                                                batch_size = BATCH,\n                                                class_mode = 'categorical',\n                                                subset = 'training')\nvalidation_set = validation_datagen.flow_from_dataframe(df,\n                                                       TRAINING_PATH,\n                                                       x_col= 'image',\n                                                       y_col = 'labels_str',\n                                                       target_size = (IMAGE_SIZE, IMAGE_SIZE),\n                                                       batch_size = BATCH,\n                                                       class_mode= 'categorical',\n                                                        subset = 'validation')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Input pipeline using tf.data","metadata":{}},{"cell_type":"code","source":"x_train, x_val,y_train, y_val = train_test_split(df.image_path,\n                                                  df.labels, test_size = 0.2)\n# x_train, x_resize, y_train, y_resize = train_test_split(x_train, y_train, test_size = 0.5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train.shape, x_val.shape, #x_resize.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train[790], y_train[790]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"list_of_image_path = df.image_path.values\nlabels = df.labels.values\nds_train = tf.data.Dataset.from_tensor_slices((list_of_image_path, labels))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if np.random.randint(0,2, 1) == 1:\n    print('value is 1')\nelse:\n    print('values is 0')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def data_loader(filenames, labels):\n    dataset = tf.data.Dataset.from_tensor_slices((filenames, labels))\n    return dataset\n\ndef random_sizing():\n    \n    return np.random.randint(0,2,1)\n\ndef image_parse_resize(path, label):\n    image = tf.io.read_file(path)\n    image = tf.image.decode_jpeg(image, channels = 3)\n    image = tf.image.resize(image, size= [IMAGE_SIZE_CUSTOM, IMAGE_SIZE_CUSTOM])\n    image = tf.cast(image, tf.float32)/255.0\n    return image, label\n\ndef image_parse(path, label):\n    image = tf.io.read_file(path)\n    image = tf.image.decode_jpeg(image, channels = 3)\n    image = tf.image.resize(image, size= [IMAGE_SIZE, IMAGE_SIZE])\n    image = tf.cast(image, tf.float32)/255.0\n    return image, label\n\ndef data_augmentation(image, label):\n    image = tf.image.random_hue(image, 0.01)\n    image = tf.image.random_saturation(image, 0.7, 1.3)\n    image = tf.image.random_contrast(image, 0.8, 1.2)\n    image = tf.image.random_flip_left_right(image)\n    return image, label\n\ndef get_dataset_validation(filenames, labels):\n    dataset = data_loader(filenames, labels)\n    dataset = dataset.map(image_parse)\n    dataset = dataset.map(data_augmentation)\n    dataset = dataset.shuffle(SHUFFLE)\n    dataset = dataset.batch(BATCH)\n    dataset = dataset.prefetch(AUTO)\n    return dataset\n\ndef get_dataset_train(filenames, labels):\n    dataset = data_loader(filenames, labels)\n    dataset = dataset.map(image_parse)\n    dataset = dataset.map(data_augmentation)\n    dataset = dataset.shuffle(SHUFFLE)\n    dataset = dataset.batch(BATCH)\n    return dataset\n\ndef get_resized_dataset(filename, labels):\n    dataset = data_loader(filename, labels)\n    dataset = dataset.map(image_parse_resize)\n    dataset = dataset.map(data_augmentation)\n    dataset = dataset.shuffle(SHUFFLE)\n    dataset = dataset.batch(BATCH)\n    return dataset\n\n\n# The following functions is created to experiment whether the model\n# Accepts varying size images or not\n\n# def train_dataset(filename_train, labels_train, filename_resize, labels_resize):\n#     ds_train = get_dataset_train(filename_train, labels_train) \n#     ds_resize = get_resized_dataset(filename_resize, labels_resize)\n#     dataset = ds_train.concatenate(ds_resize)\n#     dataset = dataset.shuffle(SHUFFLE)\n#     return dataset","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def data_loader_two_input(filenames, labels):\n    dataset = tf.data.Dataset.from_tensor_slices((filenames, labels))\n#     label_dataset = tf.data.Dataset.from_tensor_slices(labels)\n    return dataset\n\ndef image_parse_two_input(filename, label):\n    image = tf.io.read_file(filename)\n    image = tf.image.decode_jpeg(filename)\n    image_resized = tf.image.resize(image, [IMAGE_SIZE_CUSTOM, IMAGE_SIZE_CUSTOM])\n    image_original = image\n    image_resized = tf.cast(image_resized, tf.float32)/255.0\n    image_original = tf.cast(image_original, tf.float32)/255.0\n    return image_resized, image_original, label\n    \ndef data_augmentation_two_input(image_resized, image_original, label):\n    image_resized = tf.image.random_hue(image_resized, 0.01)\n    image_resized = tf.image.random_saturation(image_resized, 0.7, 1.3)\n    image_resized = tf.image.random_contrast(image_resized, 0.8, 1.2)\n    image_resized = tf.image.random_flip_left_right(image_resized)\n    \n    image_original = tf.image.random_hue(image_original, 0.01)\n    image_original = tf.image.random_saturation(image_original, 0.7, 1.3)\n    image_original = tf.image.random_contrast(image_original, 0.8, 1.2)\n    image_original = tf.image.random_flip_left_right(image_original)\n    return image_resized, image_original, label\n    \n\ndef dataset_for_two_input_model(filenames, labels):\n    dataset = data_loader_two_input(filenames, labels)\n    dataset = dataset.map(image_parse_two_input)\n    dataset = dataset.map(data_augmentation_two_input)\n    dataset = dataset.shuffle(SHUFFLE)\n    dataset = dataset.batch(BATCH)\n    \n#     image_resized, image_original, label = image_parse_two_input(file_dataset, label_dataset)\n#     image_resized, image_original, label = data_augmentation_two_input(image_resized, image_original, label)\n\n    return dataset\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_ds = train_dataset(x_train, y_train, x_resize, y_resize)\n# train_128 = get_dataset_train(x_train, y_train)\n# train_100 = get_resized_dataset(x_train, y_train)\nval_ds = get_dataset_validation(x_val, y_val)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"two_input_ds = dataset_for_two_input_model(x_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.constant([4,5]).numpy()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for image, _ in train_128:\n    print(image.shape)\n    break","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for image, _ in train_100:\n    print(image.shape)\n    break","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"row, col = 11, 5\n\nrow = min(row, BATCH//col)\nplt.figure(figsize = (20,10))\nplt.subplots(row, col, figsize = (20,10))\nfor image, label in train_100.take(2):\n    for j in range(row*col):\n        plt.subplot(row, col, j+1)\n        plt.axis('off')\n        plt.imshow(image[j])\n        plt.title(label[j].numpy())\n        plt.title(image.shape)\n        plt.tight_layout()\n    plt.show()\n    print(image.shape)\n    \n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model Building for ImageGenerator","metadata":{"execution":{"iopub.status.busy":"2022-02-19T17:46:44.64356Z","iopub.execute_input":"2022-02-19T17:46:44.644185Z","iopub.status.idle":"2022-02-19T17:46:44.647981Z","shell.execute_reply.started":"2022-02-19T17:46:44.644145Z","shell.execute_reply":"2022-02-19T17:46:44.647342Z"}}},{"cell_type":"code","source":"model = tf.keras.Sequential([\n  tf.keras.layers.Input((IMAGE_SIZE, IMAGE_SIZE, 3)) ,\n  tf.keras.layers.Conv2D(16, 5, padding='same', activation='relu'),\n  tf.keras.layers.MaxPooling2D(),\n  tf.keras.layers.Conv2D(32, 5, padding='same', activation='relu'),\n  tf.keras.layers.MaxPooling2D(),\n  tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu'),\n  tf.keras.layers.MaxPooling2D(),\n  tf.keras.layers.Flatten(),\n  tf.keras.layers.Dense(128, activation='relu'),\n  tf.keras.layers.Dense(5, activation = 'softmax')\n])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer = tf.keras.optimizers.Adam(),\n    loss= tf.keras.losses.CategoricalCrossentropy(), \n    metrics = ['accuracy'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.fit(training_set , epochs = 2, \n    validation_data = validation_set)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model for customer tf.data","metadata":{}},{"cell_type":"code","source":"model_1 = tf.keras.Sequential([\n  tf.keras.layers.Input((IMAGE_SIZE_CUSTOM, IMAGE_SIZE_CUSTOM, 3)) ,\n  tf.keras.layers.Conv2D(16, 5, padding='same', activation='relu'),\n  tf.keras.layers.MaxPooling2D(),\n  tf.keras.layers.Conv2D(32, 5, padding='same', activation='relu'),\n  tf.keras.layers.MaxPooling2D(),\n  tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu'),\n  tf.keras.layers.MaxPooling2D(),\n  tf.keras.layers.Flatten(),\n  tf.keras.layers.Dense(128, activation='relu'),\n  tf.keras.layers.Dense(5, activation = 'softmax')\n])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_1.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_1.compile(optimizer = tf.keras.optimizers.Adam(),\n    loss= tf.keras.losses.SparseCategoricalCrossentropy(), \n    metrics = ['accuracy'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_1.fit(train_ds , epochs = 2, \n    validation_data = val_ds)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image = tf.io.read_file(df.image_path[5])\nimage = tf.image.decode_jpeg(image)\nimage = tf.image.resize(image, [IMAGE_SIZE_CUSTOM, IMAGE_SIZE_CUSTOM])\nimage = tf.cast(image, tf.float32)/255.0","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(image)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image = tf.reshape(image, [-1, IMAGE_SIZE_CUSTOM, IMAGE_SIZE_CUSTOM, 3])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_1.predict(image)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model with two different sized images","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# input = keras.Input(shape = (None,))\n# if input.shape == (128,128,3):\n#     input.add(keras.layers.Conv2D(3, 29, activation = 'relu'))\n# else:\n#     x = input\n# def larger_size(input = input):\n#     return input.add(tf.keras.layers.Conv2D(3,29,activation = 'relu'))\n# def small_size(input= input):\n#     return input\n# x = tf.cond(input.shape == (128,128,3), lambda : large_size(input), lambda : small_size(input))\n\norig_input = tf.keras.layers.Input(shape = (128,128,3), name= 'Original sized')\ny = tf.keras.layers.Conv2D(6,29, activation = 'relu')(orig_input)\n\ninput_resized = tf.keras.layers.Input(shape = (100,100,3), name = 'resized')\n\nx = tf.keras.layers.Concatenate()([input_resized, y])\n    \n# x = tf.keras.layers.Reshape((100,100,6))(x)\nx = tf.keras.layers.Conv2D(16, 5, activation='relu')(x)\nx = tf.keras.layers.MaxPooling2D()(x)\nx = tf.keras.layers.Conv2D(32, 5, padding='same', activation='relu')(x)\nx = tf.keras.layers.MaxPooling2D()(x)\nx = tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu')(x)\nx = tf.keras.layers.MaxPooling2D()(x)\nx = tf.keras.layers.Flatten()(x)\nx = tf.keras.layers.Dense(128, activation='relu')(x)\noutput = tf.keras.layers.Dense(5, activation = 'softmax')(x)\nmodel_resize = keras.Model(inputs = [orig_input ,input_resized] , outputs = output)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_resize.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"keras.utils.plot_model(model_resize, show_shapes=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_resize.compile(optimizer = tf.keras.optimizers.Adam(),\n    loss= tf.keras.losses.SparseCategoricalCrossentropy(), \n    metrics = ['accuracy'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_resize.fit(two_input_ds, epochs = 2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}